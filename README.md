# Project Skeleton - Structured ML/DL Project Template

Template di progetto strutturato per Machine Learning/Deep Learning con PyTorch. Implementa best practices per organizzazione, riproducibilitÃ  e collaborazione.

**Forked from:** `iurada/project-skeleton:main`

---

## ğŸ“ Struttura del Progetto

```
polito-aml-project_skeleton/
â”œâ”€â”€ checkpoints/                  # ğŸ’¾ MODEL CHECKPOINTS (created during training)
â”‚   â”œâ”€â”€ .gitkeep                  # Mantiene cartella in git
â”‚   â”œâ”€â”€ best_model.pth            # Best model salvato automaticamente (gitignored)
â”‚   â””â”€â”€ checkpoint_epoch_N.pth    # Checkpoint periodici (gitignored)
â”‚
â”œâ”€â”€ data/                         # ğŸ“ DATASET FILES (gitignored - download separately)
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ training_set/             # Training images (cats/, dogs/)
â”‚   â””â”€â”€ test_set/                 # Test images (cats/, dogs/)
|
â”œâ”€â”€ dataset/                      # ğŸ“¦ DATASET MODULE
â”‚   â”œâ”€â”€ __init__.py               # Exports: CustomImageDataset, create_annotations_csv
â”‚   â””â”€â”€ custom_dataset.py         # PyTorch Dataset class per caricamento dati da CSV
â”‚
â”œâ”€â”€ models/                       # ğŸ§  MODELS MODULE
â”‚   â”œâ”€â”€ __init__.py               # Exports: create_name_model
â”‚   â””â”€â”€ vgg_finetuning.py         # Architetture modelli
â”‚
â”œâ”€â”€ utils/                        # ğŸ› ï¸ UTILITIES MODULE
â”‚   â”œâ”€â”€ __init__.py               # Exports: transforms, visualization, metrics functions
|   â”œâ”€â”€ download_dataset.py       # DATASET DOWNLOADER (scarica dataset, es da Kaggle)
â”‚   â”œâ”€â”€ transforms.py             # Data augmentation e preprocessing (train/val/test)
â”‚   â”œâ”€â”€ visualization.py          # Plotting e visualizzazioni (denormalize, plot curves)
â”‚   â””â”€â”€ metrics.py                # Calcolo metriche e statistiche dataset
â”‚
â”œâ”€â”€ train.py                      # ğŸš‚ TRAINING SCRIPT (main training loop con CLI)
â”œâ”€â”€ eval.py                       # ğŸ“Š EVALUATION SCRIPT (test set evaluation con CLI)
â”œâ”€â”€ config.py                     # âš™ï¸ CONFIGURATION (hyperparameters e settings centrali)
â”‚
â”œâ”€â”€ colab_training.ipynb          # ğŸ““ GOOGLE COLAB NOTEBOOK (training su Colab)
â”œâ”€â”€ requirements.txt              # ğŸ“‹ PYTHON DEPENDENCIES (pip install -r requirements.txt)
â”œâ”€â”€ .gitignore                    # ğŸš« GIT IGNORE (data/, checkpoints/*.pth, *.csv, wandb/)
â”‚
â””â”€â”€ README.md                     
```

---

## ğŸ¯ Best Practices Implementate

âœ… **ModularitÃ **: Codice diviso in moduli riutilizzabili

âœ… **CLI Interface**: Argparse per tutti gli script
   - **Cos'Ã¨?** Command-Line Interface permette di eseguire gli script da terminale passando parametri come opzioni (es: `--epochs 10 --lr 0.001`)
   - **Vantaggi:** Non devi modificare il codice per ogni esperimento, tutti i parametri sono configurabili da riga di comando
   - **Implementazione:** Usa `argparse` in Python per definire tutti gli argomenti disponibili (data_dir, epochs, batch_size, learning rate, ecc.)

âœ… **Reproducibility**: requirements.txt + config.py
   - **config.py** definisce valori di default e costanti del progetto
   - **CLI arguments** permettono di sovrascrivere i default senza modificare il codice
   - I due approcci sono complementari: config.py Ã¨ il "centro di controllo", CLI dÃ  flessibilitÃ  per esperimenti

âœ… **Checkpoint Management**: Auto-save best model

âœ… **Logging**: Wandb integration

âœ… **Documentation**: Docstrings + README completo

âœ… **Git-friendly**: .gitignore appropriato

âœ… **Data Augmentation**: Solo su train, non su val/test

âœ… **Separation of Concerns**: train.py vs eval.py

---

## ğŸ” Per AI Assistants

**Questo progetto segue una struttura modulare standard:**

1. **Dataset Module** (`dataset/`): Gestione caricamento dati
2. **Models Module** (`models/`): Architetture e model creation
3. **Utils Module** (`utils/`): Transforms, visualization, metrics
4. **Training Script** (`train.py`): Main training loop con CLI
5. **Eval Script** (`eval.py`): Test set evaluation
6. **Config** (`config.py`): Centralized configuration

**Key Points:**
- Ogni modulo ha `__init__.py` con exports espliciti
- CLI scripts usano argparse
- Training (train/validate/test functions)
- Checkpoint management automatico
- Wandb integration opzionale ma completa
- Transforms: AUGMENTATION solo su train!

**Quando suggerire modifiche:**
- Aggiungere nuovi modelli â†’ `models/new_model.py`
- Nuove metriche â†’ `utils/metrics.py`
- Nuovi datasets â†’ `dataset/new_dataset.py`
- Training modifications â†’ `train.py` (maintain CLI style)

---

## ğŸ¤ Contributing

Per adattare questo skeleton al tuo progetto:

1. **Dataset**: Modifica `dataset/custom_dataset.py` per il tuo formato
2. **Model**: Aggiungi la tua architettura in `models/`
3. **Config**: Aggiorna `config.py` con i tuoi parametri
4. **Training**: Modifica `train.py` se necessario (mantieni CLI)
5. **Update README**: Documenta le modifiche

---

## ğŸš« Git Ignore (`.gitignore`)

**Cosa ignora:**
- `data/` - Dataset (troppo grande, download separato)
- `checkpoints/*.pth` - Model checkpoints (troppo grandi)
- `*.csv` - Annotation files (generati automaticamente)
- `wandb/` - Wandb logs (sincronizzati su cloud)
- `__pycache__/` - Python cache
- `.DS_Store` - macOS files

**Cosa traccia:**
- Codice sorgente (`.py`)
- Configurazioni
- README e docs
- `.gitkeep` per cartelle vuote

---

## ğŸ”„ Workflow Tipico

### 1. Setup Iniziale
```bash
git clone <repo-url>
cd polito-aml-project_skeleton
pip install -r requirements.txt
python download_dataset.py
```

### 2. Training
```bash
# Feature extraction (base frozen)
python train.py --data_dir ./data --epochs 10 --freeze_base --use_wandb

# Full fine-tuning (tutto trainable)
python train.py --data_dir ./data --epochs 10 --use_wandb
```

### 3. Evaluation
```bash
python eval.py --checkpoint ./checkpoints/best_model.pth --data_dir ./data
```

### 4. Experiments
```bash
# Esperimento con LR diverso
python train.py --lr 0.001 --batch_size 64 --use_wandb

# Tutti gli esperimenti tracciati su Wandb!
```

---

## ğŸ“¢ Informazioni di rilascio

**ğŸ“… Ultimo aggiornamento:** Novembre 2025  
**ğŸ·ï¸ Versione:** v1.0.0 â€” Prima release stabile

*Per dettagli sui cambiamenti e le correzioni, consulta il changelog nel repository.*
